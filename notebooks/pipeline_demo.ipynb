{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad2b566d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\user\\anaconda3\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.10.0,>=2023.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (2025.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (3.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (1.26.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f20adde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Amazon Product Reviews dataset...\n",
      "Original dataset size: 6000\n",
      "\n",
      "Available columns:\n",
      "['brand', 'primaryCategories', 'reviews.numHelpful', 'reviews.rating', 'reviews.text']\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "print(\"Loading Amazon Product Reviews dataset...\")\n",
    "dataset = load_dataset(\"m-ric/amazon_product_reviews_datafiniti\")\n",
    "\n",
    "# Convert to pandas DataFrame for easier manipulation\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "print(f\"Original dataset size: {len(df)}\")\n",
    "print(\"\\nAvailable columns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99615338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in the dataset:\n",
      "['brand', 'primaryCategories', 'reviews.numHelpful', 'reviews.rating', 'reviews.text']\n",
      "\n",
      "Total columns: 5\n",
      "\n",
      "First row sample:\n",
      "brand                                     2\n",
      "primaryCategories           Health & Beauty\n",
      "reviews.numHelpful                      NaN\n",
      "reviews.rating                            5\n",
      "reviews.text          always need batteries\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# See what columns are actually available\n",
    "print(\"Available columns in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\nTotal columns: {len(df.columns)}\")\n",
    "\n",
    "# look at the first row to understand the structure\n",
    "print(\"\\nFirst row sample:\")\n",
    "print(df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b304a4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sample and structure:\n",
      "First review text: Amazon's batteries are great. I've had no problems with them leaking or corroding. They last as long as any other AA battery I've used too.The AmazonBasics brand has been great for so many different things, and I definitely recommend these batteries.\n",
      "First review rating: 5\n",
      "Brand: 2\n",
      "Primary Category: Health & Beauty\n",
      "\n",
      "Rating distribution:\n",
      "1     502\n",
      "2     306\n",
      "3     627\n",
      "4    2786\n",
      "5    1779\n",
      "Name: reviews.rating, dtype: int64\n",
      "\n",
      "Total reviews: 6000\n"
     ]
    }
   ],
   "source": [
    "# explore the dataset with the correct columns\n",
    "print(\"Dataset sample and structure:\")\n",
    "print(f\"First review text: {df['reviews.text'].iloc[0]}\")\n",
    "print(f\"First review rating: {df['reviews.rating'].iloc[0]}\")\n",
    "print(f\"Brand: {df['brand'].iloc[0]}\")\n",
    "print(f\"Primary Category: {df['primaryCategories'].iloc[0]}\")\n",
    "\n",
    "print(\"\\nRating distribution:\")\n",
    "rating_counts = df['reviews.rating'].value_counts().sort_index()\n",
    "print(rating_counts)\n",
    "\n",
    "print(f\"\\nTotal reviews: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee04bde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in key columns:\n",
      "reviews.text: 0 missing\n",
      "reviews.rating: 0 missing\n",
      "brand: 0 missing\n",
      "primaryCategories: 0 missing\n",
      "\n",
      "Total rows in dataset: 6000\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in key columns\n",
    "print(\"Missing values in key columns:\")\n",
    "print(f\"reviews.text: {df['reviews.text'].isna().sum()} missing\")\n",
    "print(f\"reviews.rating: {df['reviews.rating'].isna().sum()} missing\")\n",
    "print(f\"brand: {df['brand'].isna().sum()} missing\")\n",
    "print(f\"primaryCategories: {df['primaryCategories'].isna().sum()} missing\")\n",
    "\n",
    "print(f\"\\nTotal rows in dataset: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a56400a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "After cleaning: 4158 reviews\n",
      "Positive reviews available: 3463\n",
      "Negative reviews available: 695\n",
      "\n",
      "Final processed dataset size: 300\n",
      "\n",
      "Class distribution:\n",
      "1    150\n",
      "0    150\n",
      "Name: label, dtype: int64\n",
      "Positive reviews: 150\n",
      "Negative reviews: 150\n"
     ]
    }
   ],
   "source": [
    "# Define the preprocessing function\n",
    "def preprocess_reviews_data(df, sample_size=300):\n",
    "    \"\"\"\n",
    "    Preprocess the Amazon reviews dataset for sentiment classification\n",
    "    \"\"\"\n",
    "    # Create a clean DataFrame with only the columns we need\n",
    "    clean_data = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        review_text = row.get('reviews.text', '')\n",
    "        review_rating = row.get('reviews.rating', None)\n",
    "        \n",
    "        # Skip rows with missing text or rating\n",
    "        if not review_text or pd.isna(review_rating) or review_text == '':\n",
    "            continue\n",
    "            \n",
    "        # Convert rating to binary sentiment\n",
    "        if review_rating in [4, 5]:\n",
    "            sentiment = 1  # Positive\n",
    "        elif review_rating in [1, 2]:\n",
    "            sentiment = 0  # Negative\n",
    "        else:\n",
    "            continue  # Skip 3-star (neutral) reviews\n",
    "            \n",
    "        clean_data.append({\n",
    "            'text': str(review_text).strip().lower(),\n",
    "            'label': sentiment,\n",
    "            'rating': review_rating,\n",
    "            'brand': row.get('brand', 'unknown'),\n",
    "            'category': row.get('primaryCategories', 'unknown')\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    clean_df = pd.DataFrame(clean_data)\n",
    "    \n",
    "    # Remove duplicates and very short reviews\n",
    "    clean_df = clean_df.drop_duplicates(subset=['text'])\n",
    "    clean_df = clean_df[clean_df['text'].str.len() > 10]\n",
    "    \n",
    "    print(f\"After cleaning: {len(clean_df)} reviews\")\n",
    "    \n",
    "    # Balance the classes and take a sample\n",
    "    positive_reviews = clean_df[clean_df['label'] == 1]\n",
    "    negative_reviews = clean_df[clean_df['label'] == 0]\n",
    "    \n",
    "    print(f\"Positive reviews available: {len(positive_reviews)}\")\n",
    "    print(f\"Negative reviews available: {len(negative_reviews)}\")\n",
    "    \n",
    "    # Take equal samples from each class (adjust if one class has fewer)\n",
    "    n_each = min(len(positive_reviews), len(negative_reviews), sample_size // 2)\n",
    "    \n",
    "    balanced_df = pd.concat([\n",
    "        positive_reviews.sample(n_each, random_state=42),\n",
    "        negative_reviews.sample(n_each, random_state=42)\n",
    "    ])\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "# Now apply preprocessing\n",
    "print(\"Preprocessing data...\")\n",
    "processed_df = preprocess_reviews_data(df, sample_size=300)\n",
    "\n",
    "print(f\"\\nFinal processed dataset size: {len(processed_df)}\")\n",
    "print(\"\\nClass distribution:\")\n",
    "print(processed_df['label'].value_counts())\n",
    "print(f\"Positive reviews: {(processed_df['label'] == 1).sum()}\")\n",
    "print(f\"Negative reviews: {(processed_df['label'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65095ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 210, Test: 90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    processed_df, \n",
    "    test_size=0.3, \n",
    "    random_state=42,\n",
    "    stratify=processed_df['label']\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "961217e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING NAIVE BASELINE ON RANDOM REVIEWS:\n",
      "============================================================\n",
      "\n",
      "Example 1:\n",
      "Review: great quality batteries. comes in a small box, perfect for storing.\n",
      "True Rating: 5 stars ‚Üí True Label: POSITIVE\n",
      "Predicted: POSITIVE\n",
      "Keywords found: 2 positive, 0 negative\n",
      "Correct? ‚úÖ YES\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Review: best product value , amazon know what they doing (:good price for quantity , for sure will buy more .\n",
      "True Rating: 5 stars ‚Üí True Label: POSITIVE\n",
      "Predicted: POSITIVE\n",
      "Keywords found: 2 positive, 0 negative\n",
      "Correct? ‚úÖ YES\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Review: amazon kindle fire has a lot of free app and can be used by any one that wants to get online anywhere\n",
      "True Rating: 4 stars ‚Üí True Label: POSITIVE\n",
      "Predicted: NEGATIVE\n",
      "Keywords found: 0 positive, 0 negative\n",
      "Correct? ‚ùå NO\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "Review: i'm planning on returning this tablet just as soon as i can!`\n",
      "True Rating: 2 stars ‚Üí True Label: NEGATIVE\n",
      "Predicted: NEGATIVE\n",
      "Keywords found: 0 positive, 0 negative\n",
      "Correct? ‚úÖ YES\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "Review: hard to connect to the internet. extremely slow to load apps. not many free apps like apple. the only thing i really like is the protection it offers.\n",
      "True Rating: 1 stars ‚Üí True Label: NEGATIVE\n",
      "Predicted: NEGATIVE\n",
      "Keywords found: 0 positive, 0 negative\n",
      "Correct? ‚úÖ YES\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 6:\n",
      "Review: these might be ok for remote controls and wall clocks that don't take much power. but don't expect to use them in you digital camera. the low battery warning comes on the instant i turned on my canon 120is point and shoot camera with afresh pair of these batteries. within about 2 minutes the camera dies and won't restart without another fresh set of batteries.\n",
      "True Rating: 2 stars ‚Üí True Label: NEGATIVE\n",
      "Predicted: NEGATIVE\n",
      "Keywords found: 0 positive, 0 negative\n",
      "Correct? ‚úÖ YES\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the baseline on RANDOM examples\n",
    "class NaiveBaseline:\n",
    "    def __init__(self):\n",
    "        self.positive_words = ['great', 'good', 'excellent', 'love', 'awesome', 'perfect', 'best', 'recommend']\n",
    "        self.negative_words = ['bad', 'terrible', 'awful', 'hate', 'worst', 'waste', 'broken', 'disappointed']\n",
    "    \n",
    "    def predict(self, text):\n",
    "        text = text.lower()\n",
    "        pos_count = sum(1 for word in self.positive_words if word in text)\n",
    "        neg_count = sum(1 for word in self.negative_words if word in text)\n",
    "        \n",
    "        return 1 if pos_count > neg_count else 0\n",
    "\n",
    "# Create the baseline classifier\n",
    "baseline = NaiveBaseline()\n",
    "\n",
    "# Test on RANDOM examples from your dataset\n",
    "print(\"TESTING NAIVE BASELINE ON RANDOM REVIEWS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get 6 random examples (3 positive, 3 negative)\n",
    "random_positive = processed_df[processed_df['label'] == 1].sample(3, random_state=None)  # None = different each time\n",
    "random_negative = processed_df[processed_df['label'] == 0].sample(3, random_state=None)\n",
    "\n",
    "sample_reviews = pd.concat([random_positive, random_negative])\n",
    "\n",
    "# Test each review\n",
    "for i, (index, review) in enumerate(sample_reviews.iterrows()):\n",
    "    text = review['text']\n",
    "    true_label = review['label']\n",
    "    predicted_label = baseline.predict(text)\n",
    "    \n",
    "    # Count keywords found\n",
    "    pos_count = sum(1 for word in baseline.positive_words if word in text.lower())\n",
    "    neg_count = sum(1 for word in baseline.negative_words if word in text.lower())\n",
    "    \n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Review: {text[:10000]}\")\n",
    "    print(f\"True Rating: {review['rating']} stars ‚Üí True Label: {'POSITIVE' if true_label == 1 else 'NEGATIVE'}\")\n",
    "    print(f\"Predicted: {'POSITIVE' if predicted_label == 1 else 'NEGATIVE'}\")\n",
    "    print(f\"Keywords found: {pos_count} positive, {neg_count} negative\")\n",
    "    print(f\"Correct? {'‚úÖ YES' if true_label == predicted_label else '‚ùå NO'}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39e5d7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING RANDOM TRICKY CASES:\n",
      "============================================================\n",
      "\n",
      "Mixed Sentiment Example 1:\n",
      "Text: really good price for a reason, first two batteries i used were dead. do not waste your money!\n",
      "True Rating: 1 stars ‚Üí True Label: NEGATIVE\n",
      "Predicted: NEGATIVE\n",
      "Keywords found: 1 positive, 1 negative\n",
      "Correct? ‚úÖ YES\n",
      "--------------------------------------------------\n",
      "\n",
      "Mixed Sentiment Example 2:\n",
      "Text: it's not bad for the novelty of alexa. might as well get the echo. sound it not bad and i'm no audiophile. might be good when my echo dots come in. is it worth it? there are better bluetooth speakers out there.\n",
      "True Rating: 4 stars ‚Üí True Label: POSITIVE\n",
      "Predicted: NEGATIVE\n",
      "Keywords found: 1 positive, 1 negative\n",
      "Correct? ‚ùå NO\n",
      "--------------------------------------------------\n",
      "\n",
      "Mixed Sentiment Example 3:\n",
      "Text: the tap is a great concept, i love my echo so a portable one was that much better. however the sound is pretty terrible, no bass and can be scratchy.. it was a good concept just poor execution.\n",
      "True Rating: 2 stars ‚Üí True Label: NEGATIVE\n",
      "Predicted: POSITIVE\n",
      "Keywords found: 3 positive, 1 negative\n",
      "Correct? ‚ùå NO\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Let's also test some tricky cases with random sampling\n",
    "print(\"\\nTESTING RANDOM TRICKY CASES:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find reviews that contain both positive and negative words (mixed sentiment)\n",
    "mixed_reviews = []\n",
    "for index, row in processed_df.iterrows():\n",
    "    text = row['text'].lower()\n",
    "    pos_count = sum(1 for word in baseline.positive_words if word in text)\n",
    "    neg_count = sum(1 for word in baseline.negative_words if word in text)\n",
    "    \n",
    "    # Look for reviews that have both positive and negative keywords\n",
    "    if pos_count > 0 and neg_count > 0:\n",
    "        mixed_reviews.append((index, row, pos_count, neg_count))\n",
    "\n",
    "# Take 3 random mixed reviews\n",
    "if mixed_reviews:\n",
    "    import random\n",
    "    random_mixed = random.sample(mixed_reviews, min(3, len(mixed_reviews)))\n",
    "    \n",
    "    for i, (index, review, pos_count, neg_count) in enumerate(random_mixed):\n",
    "        predicted = baseline.predict(review['text'])\n",
    "        \n",
    "        print(f\"\\nMixed Sentiment Example {i+1}:\")\n",
    "        print(f\"Text: {review['text'][:10000]}\")\n",
    "        print(f\"True Rating: {review['rating']} stars ‚Üí True Label: {'POSITIVE' if review['label'] == 1 else 'NEGATIVE'}\")\n",
    "        print(f\"Predicted: {'POSITIVE' if predicted == 1 else 'NEGATIVE'}\")\n",
    "        print(f\"Keywords found: {pos_count} positive, {neg_count} negative\")\n",
    "        print(f\"Correct? {'‚úÖ YES' if review['label'] == predicted else '‚ùå NO'}\")\n",
    "        print(\"-\" * 50)\n",
    "else:\n",
    "    print(\"No mixed sentiment reviews found in this sample.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e5cf025",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING NAIVE BASELINE ON ENTIRE TEST SET:\n",
      "============================================================\n",
      "Overall Baseline Accuracy: 0.756\n",
      "\n",
      "Detailed Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.91      0.79        45\n",
      "    positive       0.87      0.60      0.71        45\n",
      "\n",
      "    accuracy                           0.76        90\n",
      "   macro avg       0.78      0.76      0.75        90\n",
      "weighted avg       0.78      0.76      0.75        90\n",
      "\n",
      "\n",
      "RANDOM CORRECT AND INCORRECT PREDICTIONS:\n",
      "============================================================\n",
      "CORRECT PREDICTIONS:\n",
      "\n",
      "Correct Example 1:\n",
      "Text: wore out quickly\n",
      "True: NEGATIVE, Predicted: NEGATIVE\n",
      "\n",
      "Correct Example 2:\n",
      "Text: good deal for rechargeable. they all work and seem to preform well.\n",
      "True: POSITIVE, Predicted: POSITIVE\n",
      "\n",
      "INCORRECT PREDICTIONS:\n",
      "\n",
      "Incorrect Example 1:\n",
      "Text: i don't recommend buying this. after 1 month of buying this, it won't charge or turn on.\n",
      "True: NEGATIVE, Predicted: POSITIVE\n",
      "\n",
      "Incorrect Example 2:\n",
      "Text: better than buying 12 duracell betters for the same price. used primarily for my kids toys.\n",
      "True: POSITIVE, Predicted: NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "# Run the baseline on the entire test set to get overall accuracy\n",
    "print(\"\\nEVALUATING NAIVE BASELINE ON ENTIRE TEST SET:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Get predictions for all test examples\n",
    "y_true = test_df['label'].tolist()\n",
    "y_pred_baseline = []\n",
    "for text in test_df['text']:\n",
    "    y_pred_baseline.append(baseline.predict(text))\n",
    "\n",
    "# Calculate overall accuracy\n",
    "baseline_accuracy = accuracy_score(y_true, y_pred_baseline)\n",
    "print(f\"Overall Baseline Accuracy: {baseline_accuracy:.3f}\")\n",
    "\n",
    "# Detailed performance report\n",
    "print(\"\\nDetailed Performance Report:\")\n",
    "print(classification_report(y_true, y_pred_baseline, target_names=['negative', 'positive']))\n",
    "\n",
    "# Show some random correct and incorrect predictions\n",
    "print(\"\\nRANDOM CORRECT AND INCORRECT PREDICTIONS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Add predictions to test_df for analysis\n",
    "test_df_with_pred = test_df.copy()\n",
    "test_df_with_pred['predicted'] = y_pred_baseline\n",
    "test_df_with_pred['correct'] = test_df_with_pred['label'] == test_df_with_pred['predicted']\n",
    "\n",
    "# Get 2 correct and 2 incorrect random examples\n",
    "correct_examples = test_df_with_pred[test_df_with_pred['correct'] == True].sample(2, random_state=None)\n",
    "incorrect_examples = test_df_with_pred[test_df_with_pred['correct'] == False].sample(min(2, len(test_df_with_pred[test_df_with_pred['correct'] == False])), random_state=None)\n",
    "\n",
    "print(\"CORRECT PREDICTIONS:\")\n",
    "for i, (index, row) in enumerate(correct_examples.iterrows()):\n",
    "    print(f\"\\nCorrect Example {i+1}:\")\n",
    "    print(f\"Text: {row['text'][:10000]}\")\n",
    "    print(f\"True: {'POSITIVE' if row['label'] == 1 else 'NEGATIVE'}, Predicted: {'POSITIVE' if row['predicted'] == 1 else 'NEGATIVE'}\")\n",
    "\n",
    "print(\"\\nINCORRECT PREDICTIONS:\")\n",
    "for i, (index, row) in enumerate(incorrect_examples.iterrows()):\n",
    "    print(f\"\\nIncorrect Example {i+1}:\")\n",
    "    print(f\"Text: {row['text'][:10000]}\")\n",
    "    print(f\"True: {'POSITIVE' if row['label'] == 1 else 'NEGATIVE'}, Predicted: {'POSITIVE' if row['predicted'] == 1 else 'NEGATIVE'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3c859ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.30.0)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2025.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3170829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading DistilBERT model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "Generating embeddings for training data...\n",
      "Generating embeddings for testing data...\n",
      "Training embeddings shape: (210, 768)\n",
      "Test embeddings shape: (90, 768)\n",
      "\n",
      "Training Logistic Regression classifier on embeddings...\n",
      "\n",
      "============================================================\n",
      "AI PIPELINE PERFORMANCE\n",
      "============================================================\n",
      "Overall AI Pipeline Accuracy: 0.856\n",
      "\n",
      "Detailed Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86        45\n",
      "    positive       0.86      0.84      0.85        45\n",
      "\n",
      "    accuracy                           0.86        90\n",
      "   macro avg       0.86      0.86      0.86        90\n",
      "weighted avg       0.86      0.86      0.86        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# AI PIPELINE IMPLEMENTATION\n",
    "# =============================================================================\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "print(\"Loading DistilBERT model and tokenizer...\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Function to get embeddings from the model\n",
    "def get_embeddings(texts, batch_size=16):\n",
    "    \"\"\"\n",
    "    Get [CLS] token embeddings for a list of texts in batches to save memory\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize the batch\n",
    "        inputs = tokenizer(\n",
    "            batch_texts, \n",
    "            return_tensors='pt', \n",
    "            truncation=True, \n",
    "            padding=True, \n",
    "            max_length=128\n",
    "        )\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():  # Disable gradient calculation for inference\n",
    "            outputs = model(**inputs)\n",
    "            # Extract the [CLS] token embedding (first token)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "            embeddings.append(cls_embeddings.cpu().numpy())\n",
    "    \n",
    "    # Combine all batches\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "print(\"\\nGenerating embeddings for training data...\")\n",
    "# Generate embeddings for the training texts\n",
    "X_train_embeddings = get_embeddings(train_df['text'].tolist())\n",
    "y_train = train_df['label'].tolist()\n",
    "\n",
    "print(\"Generating embeddings for testing data...\")\n",
    "# Generate embeddings for the testing texts\n",
    "X_test_embeddings = get_embeddings(test_df['text'].tolist())\n",
    "y_test = test_df['label'].tolist()\n",
    "\n",
    "print(f\"Training embeddings shape: {X_train_embeddings.shape}\")\n",
    "print(f\"Test embeddings shape: {X_test_embeddings.shape}\")\n",
    "\n",
    "# Train a classifier on the embeddings\n",
    "print(\"\\nTraining Logistic Regression classifier on embeddings...\")\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Evaluate the AI Pipeline\n",
    "y_pred_ai = clf.predict(X_test_embeddings)\n",
    "ai_accuracy = accuracy_score(y_test, y_pred_ai)\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"AI PIPELINE PERFORMANCE\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Overall AI Pipeline Accuracy: {ai_accuracy:.3f}\")\n",
    "print(\"\\nDetailed Performance Report:\")\n",
    "print(classification_report(y_test, y_pred_ai, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be629e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING AI PIPELINE ON RANDOM MIXED SENTIMENT REVIEWS\n",
      "============================================================\n",
      "\n",
      "Mixed Sentiment Example 1:\n",
      "Text: i accidentally cracked my screen on the first day when the voyage was too close to my rocking chair and neither best buy nor amazon would do anything to help. well, amazon offered $15 off purchasing the paperwhite and that wasn't something i wanted at all. now i'm stuck with a $199 broken voyage. not a happy customer. i realize it was my fault but thought they should do something more to minimize the loss and keep my business.\n",
      "True Rating: 2 stars ‚Üí True Label: NEGATIVE\n",
      "Baseline Pred: NEGATIVE\n",
      "AI Pred: NEGATIVE\n",
      "Keywords found: 1 positive, 1 negative\n",
      "Baseline: ‚úÖ, AI: ‚úÖ\n",
      "--------------------------------------------------\n",
      "\n",
      "Mixed Sentiment Example 2:\n",
      "Text: worst batteries i ever bought. less than one hour after installing in remote, popup on tv said remote battery low. left them in and got about four hours more use before it wouldn't turn on the receiver. the aa's i bought seem to be fine. not sure why the aaa's didn't last. put 4 new ones in the remote ... we'll see how these do. the second set of four were no better than the first. low battery warning after a few hours use (surfing dish tv program guide). all showed just over 1.5 volts before installation. checked again when first low battery warning came up. down to .8 volts. guess i got an old, bad batch. nothing but duracell from here on out. would not recommend these batteries !\n",
      "True Rating: 1 stars ‚Üí True Label: NEGATIVE\n",
      "Baseline Pred: NEGATIVE\n",
      "AI Pred: NEGATIVE\n",
      "Keywords found: 1 positive, 2 negative\n",
      "Baseline: ‚úÖ, AI: ‚úÖ\n",
      "--------------------------------------------------\n",
      "\n",
      "Mixed Sentiment Example 3:\n",
      "Text: very disappointed that my kindle voyage, purchased in april, failed after just two uses. went to charge it tonight to take on a business trip and it won't charge, won't reset, etc. since my best buy receipt says i only have 15 days to return it, tried calling amazon support. their only solution after over 30 minutes on the phone is to process a replacement which may be a new or may be a refurbished device-- unacceptable to replace a less than 2-month old device with a refurbished one... but, given the poor experience i've had with the voyage, i'm not even comfortable with a 'new' replacement at this point. amazon says they can't do anything about a refund because i purchased from best buy-- 15 days seems a little extreme in a situation like this with a defective product!stuck with a $200 paperweight :-(\n",
      "True Rating: 1 stars ‚Üí True Label: NEGATIVE\n",
      "Baseline Pred: NEGATIVE\n",
      "AI Pred: NEGATIVE\n",
      "Keywords found: 1 positive, 1 negative\n",
      "Baseline: ‚úÖ, AI: ‚úÖ\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "TESTING AI PIPELINE ON RANDOM REGULAR REVIEWS\n",
      "============================================================\n",
      "RANDOM REVIEW TESTING:\n",
      "\n",
      "Random Review 1:\n",
      "Text: looks nice can't wait to try it out! great price for a tablet.\n",
      "True Rating: 4 stars ‚Üí True Label: POSITIVE\n",
      "Baseline Pred: POSITIVE\n",
      "AI Pred: POSITIVE\n",
      "Baseline: ‚úÖ, AI: ‚úÖ\n",
      "--------------------------------------------------\n",
      "\n",
      "Random Review 2:\n",
      "Text: well made and work very well, so why pay name brand prices i shall buy these again!\n",
      "True Rating: 4 stars ‚Üí True Label: POSITIVE\n",
      "Baseline Pred: NEGATIVE\n",
      "AI Pred: POSITIVE\n",
      "Baseline: ‚ùå, AI: ‚úÖ\n",
      "--------------------------------------------------\n",
      "\n",
      "Random Review 3:\n",
      "Text: the tap is a great concept, i love my echo so a portable one was that much better. however the sound is pretty terrible, no bass and can be scratchy.. it was a good concept just poor execution.\n",
      "True Rating: 2 stars ‚Üí True Label: NEGATIVE\n",
      "Baseline Pred: POSITIVE\n",
      "AI Pred: NEGATIVE\n",
      "Baseline: ‚ùå, AI: ‚úÖ\n",
      "--------------------------------------------------\n",
      "\n",
      "Random Review 4:\n",
      "Text: batteries dead as of june 1. i did not use half of then. good for 6 months.\n",
      "True Rating: 1 stars ‚Üí True Label: NEGATIVE\n",
      "Baseline Pred: POSITIVE\n",
      "AI Pred: NEGATIVE\n",
      "Baseline: ‚ùå, AI: ‚úÖ\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETE!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RANDOM CORRECT AND INCORRECT PREDICTIONS FROM AI PIPELINE:\n",
      "============================================================\n",
      "CORRECT AI PREDICTIONS:\n",
      "\n",
      "Correct AI Example 1:\n",
      "Text: not a very good battery. they drain really fast. i use them in my roku remote. i plug my headphones into the remote for wireless listening, so i'm not sure if that is a factor. but i've used several different batteries in the remote and none of them drained nearly as quick as these did. i'm talking a week and they are dead. i would not recommend them.\n",
      "True: NEGATIVE, AI Predicted: NEGATIVE\n",
      "Rating: 2 stars\n",
      "--------------------------------------------------\n",
      "\n",
      "Correct AI Example 2:\n",
      "Text: maybe i received a defective batch but these are so bad.no longevity at all. used up within 2 weeks whereas the branded ones last 2 months!i will not purchase them again regardless of the lower cost.\n",
      "True: NEGATIVE, AI Predicted: NEGATIVE\n",
      "Rating: 1 stars\n",
      "--------------------------------------------------\n",
      "\n",
      "INCORRECT AI PREDICTIONS:\n",
      "\n",
      "Incorrect AI Example 1:\n",
      "Text: i am a power user; there's no other way of putting it. i work in it and i research the heck out of products before i buy. i had an ipad mini 2 that was just not up to snuff with ios 10 so i sold it and bought (and eventually returned) the 2016 fire hd 8. first let me say it's a great tablet for the price and for probably 50-60% of tablet users who surf the web and watch netflix. it also helps if you are a heavy amazon content user. for me, i was spoiled by the retina display on the ipad. the 720p display is alright, but you can see the pixels. 189ppi is pretty low by today's standards. the other big thing for me was the lack of a laminated display. it's glare city on this thing. display nitpicks aside, it punches above its price point. if you don't play really heavy games (which it even plays titan quest surprisingly well!) and you don't mind not having an absolutely beautiful screen i think it runs and works fine. it just wasn't for me. i bit the bullet and went with a 128gb ipad air 2 as its on special at bb for super cheap right now.\n",
      "True: POSITIVE, AI Predicted: NEGATIVE\n",
      "Rating: 4 stars\n",
      "--------------------------------------------------\n",
      "\n",
      "Incorrect AI Example 2:\n",
      "Text: just okay! product was for my girlfriend. doesn't appear she uses it much except to steam music. most of the questions i ask it i get nothing. i like siri better.\n",
      "True: NEGATIVE, AI Predicted: POSITIVE\n",
      "Rating: 2 stars\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "FINAL SUMMARY\n",
      "============================================================\n",
      "Total Test Reviews: 90\n",
      "Correct AI Predictions: 77 (85.6%)\n",
      "Incorrect AI Predictions: 13 (14.4%)\n",
      "Final AI Pipeline Accuracy: 0.856\n",
      "Baseline Accuracy: 0.756\n",
      "Improvement: +0.100 (10.0%)\n",
      "\n",
      "üí° Random Insight: AI correctly classified 77 out of 90 reviews\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "üí° TIP: Run this code again to see different random examples!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST AI PIPELINE ON RANDOM TRICKY CASES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"TESTING AI PIPELINE ON RANDOM MIXED SENTIMENT REVIEWS\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# Find NEW random mixed sentiment reviews each time\n",
    "mixed_reviews_new = []\n",
    "for index, row in processed_df.iterrows():\n",
    "    text = row['text'].lower()\n",
    "    pos_count = sum(1 for word in baseline.positive_words if word in text)\n",
    "    neg_count = sum(1 for word in baseline.negative_words if word in text)\n",
    "    \n",
    "    # Look for reviews that have both positive and negative keywords\n",
    "    if pos_count > 0 and neg_count > 0:\n",
    "        mixed_reviews_new.append((index, row, pos_count, neg_count))\n",
    "\n",
    "# Take 3 RANDOM mixed reviews (different each time)\n",
    "if mixed_reviews_new:\n",
    "    random_mixed_new = random.sample(mixed_reviews_new, min(3, len(mixed_reviews_new)))\n",
    "    \n",
    "    for i, (index, review, pos_count, neg_count) in enumerate(random_mixed_new):\n",
    "        # Get AI prediction\n",
    "        review_embedding = get_embeddings([review['text']])\n",
    "        ai_prediction = clf.predict(review_embedding)[0]\n",
    "        \n",
    "        print(f\"\\nMixed Sentiment Example {i+1}:\")\n",
    "        print(f\"Text: {review['text'][:10000]}\")\n",
    "        print(f\"True Rating: {review['rating']} stars ‚Üí True Label: {'POSITIVE' if review['label'] == 1 else 'NEGATIVE'}\")\n",
    "        print(f\"Baseline Pred: {'POSITIVE' if baseline.predict(review['text']) == 1 else 'NEGATIVE'}\")\n",
    "        print(f\"AI Pred: {'POSITIVE' if ai_prediction == 1 else 'NEGATIVE'}\")\n",
    "        print(f\"Keywords found: {pos_count} positive, {neg_count} negative\")\n",
    "        baseline_correct = '‚úÖ' if baseline.predict(review['text']) == review['label'] else '‚ùå'\n",
    "        ai_correct = '‚úÖ' if ai_prediction == review['label'] else '‚ùå'\n",
    "        print(f\"Baseline: {baseline_correct}, AI: {ai_correct}\")\n",
    "        print(\"-\" * 50)\n",
    "else:\n",
    "    print(\"No mixed sentiment reviews found in this sample.\")\n",
    "\n",
    "# =============================================================================\n",
    "# TEST ON RANDOM REGULAR REVIEWS (POSITIVE AND NEGATIVE)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"TESTING AI PIPELINE ON RANDOM REGULAR REVIEWS\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# Get 2 random positive and 2 random negative reviews (different each time)\n",
    "random_positive = processed_df[processed_df['label'] == 1].sample(2, random_state=None)\n",
    "random_negative = processed_df[processed_df['label'] == 0].sample(2, random_state=None)\n",
    "random_reviews = pd.concat([random_positive, random_negative])\n",
    "\n",
    "print(\"RANDOM REVIEW TESTING:\")\n",
    "for i, (index, review) in enumerate(random_reviews.iterrows()):\n",
    "    # Get AI prediction\n",
    "    review_embedding = get_embeddings([review['text']])\n",
    "    ai_prediction = clf.predict(review_embedding)[0]\n",
    "    \n",
    "    print(f\"\\nRandom Review {i+1}:\")\n",
    "    print(f\"Text: {review['text'][:10000]}\")\n",
    "    print(f\"True Rating: {review['rating']} stars ‚Üí True Label: {'POSITIVE' if review['label'] == 1 else 'NEGATIVE'}\")\n",
    "    print(f\"Baseline Pred: {'POSITIVE' if baseline.predict(review['text']) == 1 else 'NEGATIVE'}\")\n",
    "    print(f\"AI Pred: {'POSITIVE' if ai_prediction == 1 else 'NEGATIVE'}\")\n",
    "    baseline_correct = '‚úÖ' if baseline.predict(review['text']) == review['label'] else '‚ùå'\n",
    "    ai_correct = '‚úÖ' if ai_prediction == review['label'] else '‚ùå'\n",
    "    print(f\"Baseline: {baseline_correct}, AI: {ai_correct}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# =============================================================================\n",
    "# RANDOM CORRECT AND INCORRECT PREDICTIONS FROM AI PIPELINE\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"RANDOM CORRECT AND INCORRECT PREDICTIONS FROM AI PIPELINE:\")\n",
    "print(f\"{'=' * 60}\") \n",
    "\n",
    "# Create a fresh copy with AI predictions to ensure we have the right columns\n",
    "test_analysis_df = test_df.copy()\n",
    "test_analysis_df['ai_pred'] = y_pred_ai\n",
    "test_analysis_df['ai_correct'] = test_analysis_df['label'] == test_analysis_df['ai_pred']\n",
    "\n",
    "# Get 2 correct and 2 incorrect random examples from AI (DIFFERENT EACH TIME)\n",
    "correct_ai_examples = test_analysis_df[test_analysis_df['ai_correct'] == True].sample(2, random_state=None)\n",
    "incorrect_ai_examples = test_analysis_df[test_analysis_df['ai_correct'] == False].sample(\n",
    "    min(2, len(test_analysis_df[test_analysis_df['ai_correct'] == False])), \n",
    "    random_state=None  # No fixed random state = different each time\n",
    ")\n",
    "\n",
    "print(\"CORRECT AI PREDICTIONS:\")\n",
    "for i, (index, row) in enumerate(correct_ai_examples.iterrows()):\n",
    "    print(f\"\\nCorrect AI Example {i+1}:\")\n",
    "    print(f\"Text: {row['text'][:10000]}\")\n",
    "    print(f\"True: {'POSITIVE' if row['label'] == 1 else 'NEGATIVE'}, AI Predicted: {'POSITIVE' if row['ai_pred'] == 1 else 'NEGATIVE'}\")\n",
    "    print(f\"Rating: {row['rating']} stars\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nINCORRECT AI PREDICTIONS:\")\n",
    "if len(incorrect_ai_examples) > 0:\n",
    "    for i, (index, row) in enumerate(incorrect_ai_examples.iterrows()):\n",
    "        print(f\"\\nIncorrect AI Example {i+1}:\")\n",
    "        print(f\"Text: {row['text'][:10000]}\")\n",
    "        print(f\"True: {'POSITIVE' if row['label'] == 1 else 'NEGATIVE'}, AI Predicted: {'POSITIVE' if row['ai_pred'] == 1 else 'NEGATIVE'}\")\n",
    "        print(f\"Rating: {row['rating']} stars\")\n",
    "        print(\"-\" * 50)\n",
    "else:\n",
    "    print(\"No incorrect predictions found! Perfect AI performance!\")\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL SUMMARY WITH RANDOM INSIGHTS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# Calculate some final statistics\n",
    "total_test_reviews = len(test_df)\n",
    "correct_ai_predictions = (test_analysis_df['ai_correct'] == True).sum()\n",
    "incorrect_ai_predictions = (test_analysis_df['ai_correct'] == False).sum()\n",
    "\n",
    "print(f\"Total Test Reviews: {total_test_reviews}\")\n",
    "print(f\"Correct AI Predictions: {correct_ai_predictions} ({correct_ai_predictions/total_test_reviews*100:.1f}%)\")\n",
    "print(f\"Incorrect AI Predictions: {incorrect_ai_predictions} ({incorrect_ai_predictions/total_test_reviews*100:.1f}%)\")\n",
    "print(f\"Final AI Pipeline Accuracy: {ai_accuracy:.3f}\")\n",
    "\n",
    "if 'baseline_accuracy' in locals():\n",
    "    print(f\"Baseline Accuracy: {baseline_accuracy:.3f}\")\n",
    "    improvement = ai_accuracy - baseline_accuracy\n",
    "    print(f\"Improvement: +{improvement:.3f} ({improvement*100:.1f}%)\")\n",
    "\n",
    "# Show a random interesting fact\n",
    "interesting_facts = [\n",
    "    f\"AI correctly classified {correct_ai_predictions} out of {total_test_reviews} reviews\",\n",
    "    f\"That's like getting {correct_ai_predictions} test questions right out of {total_test_reviews}\",\n",
    "    f\"The AI makes mistakes on only {incorrect_ai_predictions} reviews\",\n",
    "    f\"Run this again to see different examples of AI performance!\"\n",
    "]\n",
    "\n",
    "print(f\"\\nüí° Random Insight: {random.choice(interesting_facts)}\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üí° TIP: Run this code again to see different random examples!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52520853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPARISON: Naive Baseline vs. AI Pipeline\n",
      "============================================================\n",
      "Naive Baseline Accuracy: 0.756\n",
      "AI Pipeline Accuracy:    0.856\n",
      "Improvement:             +0.100\n",
      "\n",
      "============================================================\n",
      "EXAMPLES WHERE AI PIPELINE CORRECTS BASELINE ERRORS\n",
      "============================================================\n",
      "\n",
      "Corrected Example 1:\n",
      "Review: works as well as the name brand batteries but so much cheaper! easy to unpack also.\n",
      "True Rating: 5 stars ‚Üí True Label: POSITIVE\n",
      "Baseline Prediction: NEGATIVE\n",
      "AI Prediction: POSITIVE\n",
      "‚úÖ AI pipeline corrected baseline error!\n",
      "--------------------------------------------------\n",
      "\n",
      "Corrected Example 2:\n",
      "Review: i don't recommend buying this. after 1 month of buying this, it won't charge or turn on.\n",
      "True Rating: 1 stars ‚Üí True Label: NEGATIVE\n",
      "Baseline Prediction: POSITIVE\n",
      "AI Prediction: NEGATIVE\n",
      "‚úÖ AI pipeline corrected baseline error!\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# COMPARISON: BASELINE vs AI PIPELINE\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"COMPARISON: Naive Baseline vs. AI Pipeline\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# Use the correct variable names that you defined earlier\n",
    "print(f\"Naive Baseline Accuracy: {baseline_accuracy:.3f}\")  # Changed from 'accuracy' to 'baseline_accuracy'\n",
    "print(f\"AI Pipeline Accuracy:    {ai_accuracy:.3f}\")        # Changed from 'accuracy_ai' to 'ai_accuracy'\n",
    "print(f\"Improvement:             +{ai_accuracy - baseline_accuracy:.3f}\")\n",
    "\n",
    "# Show some examples where AI pipeline corrects baseline errors\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"EXAMPLES WHERE AI PIPELINE CORRECTS BASELINE ERRORS\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# Add AI predictions to test dataframe - use consistent variable names\n",
    "test_df_with_pred = test_df.copy()\n",
    "test_df_with_pred['baseline_pred'] = y_pred_baseline  # Changed from 'y_pred' to 'y_pred_baseline'\n",
    "test_df_with_pred['ai_pred'] = y_pred_ai              # This should be correct\n",
    "test_df_with_pred['baseline_correct'] = test_df_with_pred['label'] == test_df_with_pred['baseline_pred']\n",
    "test_df_with_pred['ai_correct'] = test_df_with_pred['label'] == test_df_with_pred['ai_pred']\n",
    "\n",
    "# Find examples where baseline was wrong but AI was right\n",
    "corrected_examples = test_df_with_pred[\n",
    "    (test_df_with_pred['baseline_correct'] == False) & \n",
    "    (test_df_with_pred['ai_correct'] == True)\n",
    "]\n",
    "\n",
    "if len(corrected_examples) > 0:\n",
    "    sample_corrected = corrected_examples.sample(min(2, len(corrected_examples)), random_state=42)\n",
    "    \n",
    "    for i, (idx, row) in enumerate(sample_corrected.iterrows()):\n",
    "        print(f\"\\nCorrected Example {i+1}:\")\n",
    "        print(f\"Review: {row['text'][:10000]}\")\n",
    "        print(f\"True Rating: {row['rating']} stars ‚Üí True Label: {'POSITIVE' if row['label'] == 1 else 'NEGATIVE'}\")\n",
    "        print(f\"Baseline Prediction: {'POSITIVE' if row['baseline_pred'] == 1 else 'NEGATIVE'}\")\n",
    "        print(f\"AI Prediction: {'POSITIVE' if row['ai_pred'] == 1 else 'NEGATIVE'}\")\n",
    "        print(\"‚úÖ AI pipeline corrected baseline error!\")\n",
    "        print(\"-\" * 50)\n",
    "else:\n",
    "    print(\"No correction examples found in this sample.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
